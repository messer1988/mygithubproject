# gradio_chat_ru_pro.py ‚Äî ChatGPT-–ø–æ–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ç–≤–æ–µ–π –º–æ–¥–µ–ª–∏ DevOps-LLM –Ω–∞ ruGPT3small

import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from pathlib import Path

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ ===
model_path = Path(__file__).resolve().parent
device = "mps" if torch.backends.mps.is_available() else "cpu"

print(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {model_path}")
print(f"üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

tokenizer = AutoTokenizer.from_pretrained(str(model_path))
model = AutoModelForCausalLM.from_pretrained(str(model_path)).to(device)
model.eval()

# === –õ–æ–≥–∏–∫–∞ –¥–∏–∞–ª–æ–≥–∞ ===
def chat(message, history):
    if history is None:
        history = []

    # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏
    dialogue = ""
    for user, bot in history:
        dialogue += f"<|prompt|> {user}\n<|answer|> {bot}\n"

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
    dialogue += f"<|prompt|> {message}\n<|answer|>"

    inputs = tokenizer(dialogue, return_tensors="pt", truncation=True, padding=True, max_length=1024).to(device)

    outputs = model.generate(
        **inputs,
        max_new_tokens=300,
        temperature=0.8,
        top_p=0.95,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id,
    )

    reply = tokenizer.decode(outputs[0], skip_special_tokens=True)
    reply = reply.split("<|answer|>")[-1].strip()

    history.append((message, reply))
    return history, history


# === UI ===
with gr.Blocks(theme=gr.themes.Soft(primary_hue="purple", secondary_hue="orange")) as demo:
    gr.Markdown(
        """
        ## ü§ñ DevOps-LLM (ruGPT3small)
        –¢–≤–æ—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è LLM-–º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ 10 000 DevOps-–ø—Ä–æ–º–ø—Ç–∞—Ö.  
        –°–ø—Ä–∞—à–∏–≤–∞–π –ø—Ä–æ Jenkins, Ansible, Helm, Nginx, Groovy –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ.
        """
    )

    chatbot = gr.Chatbot(label="–î–∏–∞–ª–æ–≥", height=500, show_label=False)
    msg = gr.Textbox(label="–°–æ–æ–±—â–µ–Ω–∏–µ", placeholder="–ù–∞–ø–∏—à–∏ –≤–æ–ø—Ä–æ—Å –∏ –Ω–∞–∂–º–∏ Enter...")
    clear = gr.Button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é")

    msg.submit(chat, [msg, chatbot], [chatbot, chatbot])
    clear.click(lambda: None, None, chatbot, queue=False)

demo.queue()
demo.launch()